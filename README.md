# Projeto 1: Classifica√ß√£o Bin√°ria de Doen√ßas Card√≠acas com Redes Neurais

**Disciplina:** Fundamentos de Intelig√™ncia Artificial (FIA)
**Professor:** Edjard Mota

## üë• Equipe

- ANDR√â MALMSTEEN OLIVEIRA AMORIM
- BENJAMIM ISAAC RIBEIRO LIMA
- DIEGO GABRIEL SILVA AZEVEDO
- GUILHERME DA SILVA PEREIRA
- LET√çCIA ARA√öJO
- MANFRED LIMA VEIGA
---

## üìã Sum√°rio
* [1. Sobre o Projeto](#1-sobre-o-projeto)
* [2. Adapta√ß√µes e Melhorias](#2-adapta√ß√µes-e-melhorias)
* [3. Fluxo de Trabalho do Notebook](#3-fluxo-de-trabalho-do-notebook)
* [4. Resultados Obtidos](#4-resultados-obtidos)
* [5. Conclus√£o](#5-conclus√£o)

---

## üí° 1. Sobre o Projeto

Este projeto consiste na implementa√ß√£o de uma Rede Neural Artificial (ANN) *feedforward* para atuar como um **classificador bin√°rio**. O objetivo √© prever a presen√ßa (1) ou aus√™ncia (0) de doen√ßa card√≠aca em um paciente com base em um conjunto de atributos cl√≠nicos.

### O Problema

As doen√ßas cardiovasculares s√£o a principal causa de morte em todo o mundo, tornando a detec√ß√£o precoce um desafio cr√≠tico para a sa√∫de p√∫blica. O desenvolvimento de modelos preditivos precisos pode auxiliar profissionais de sa√∫de a identificar pacientes em risco, permitindo interven√ß√µes mais r√°pidas e eficazes.

### O Dataset

O modelo foi treinado e avaliado utilizando o dataset **Heart Disease UCI**, obtido via Kaggle. Ap√≥s um rigoroso processo de limpeza, que incluiu a remo√ß√£o de **723 registros duplicados**, o dataset final consistiu em **302 amostras √∫nicas**.

* **Features (X):** 13 atributos cl√≠nicos, como idade, sexo, n√≠vel de colesterol (`chol`), tipo de dor no peito (`cp`) e press√£o arterial (`trestbps`).
* **Target (y):** A vari√°vel-alvo (`target`), onde 0 indica aus√™ncia de doen√ßa e 1 indica a presen√ßa.

---

## üöÄ 2. Adapta√ß√µes e Melhorias

Este notebook foi desenvolvido com base nas instru√ß√µes da disciplina (Tema1-Trabalho-RedesNeurais.pdf) e adaptado do notebook base *'Heart Disease Prediction using Neural Networks'* (dispon√≠vel no Kaggle).

Foram realizadas as seguintes modifica√ß√µes e melhorias t√©cnicas em rela√ß√£o ao c√≥digo base:

1.¬† **Foco em Classifica√ß√£o Bin√°ria:** O notebook original explorava tanto a classifica√ß√£o categ√≥rica (m√∫ltiplos n√≠veis de doen√ßa) quanto a bin√°ria. Conforme as instru√ß√µes do trabalho, este projeto foi focado estritamente na **classifica√ß√£o bin√°ria** (0 vs 1), tratando qualquer diagn√≥stico de doen√ßa como classe "1".

2.¬† **Remo√ß√£o de Duplicatas:** Foi identificada e executada a remo√ß√£o de **723 linhas duplicadas** (o dataset original do Kaggle tinha 1025 linhas), uma etapa de pr√©-processamento crucial que n√£o estava no notebook original, garantindo a integridade e a validade estat√≠stica do modelo (302 amostras restantes).

3.¬† **Implementa√ß√£o de *Early Stopping*:** Para combater o *overfitting* e otimizar o tempo de treinamento, foi adicionado um *callback* `EarlyStopping` do Keras.
¬† ¬† * O modelo foi configurado para rodar por at√© **60 √©pocas**, monitorando a `val_loss`.
¬† ¬† * O treinamento foi interrompido automaticamente na **√âpoca 31**, pois a `val_loss` n√£o melhorou por **11 √©pocas** (paci√™ncia).
¬† ¬† * Crucialmente, a op√ß√£o `restore_best_weights=True` foi ativada. Isso garante que o modelo final utilizado para avalia√ß√£o **n√£o √© o da √∫ltima √©poca (√âpoca 31)**, que j√° apresentava overfitting, mas sim o modelo com os **pesos da √âpoca 20**, que teve o menor `val_loss` (melhor generaliza√ß√£o).

---

## üß© 3. Fluxo de Trabalho do Notebook

O notebook segue o fluxo padr√£o de um projeto de *Deep Learning*:

1.¬† **Carga e Limpeza:** Os dados s√£o carregados via API do Kaggle e limpos (remo√ß√£o de 723 duplicatas).

2.¬† **An√°lise Explorat√≥ria (EDA):** Verifica√ß√£o de tipos de dados, balanceamento de classe (**54,3%** vs **45,7%**, bem balanceado) e an√°lise de correla√ß√£o.

3.¬† **Pr√©-processamento:**
¬† ¬† * Divis√£o dos dados em treino (80% / **241 amostras**) e teste (20% / **61 amostras**).
¬† ¬† * **Normaliza√ß√£o (Padroniza√ß√£o):** Aplica√ß√£o do `StandardScaler` *ap√≥s* a divis√£o (fit no treino, transform no teste) para evitar *data leakage*. Este passo √© essencial devido √†s diferentes escalas das *features* (ex: `age` vs `chol`).
    
4.¬† **Constru√ß√£o do Modelo (Keras):** A ANN foi constru√≠da com:
¬† ¬† * Camada de Entrada (13 neur√¥nios)
¬† ¬† * 2 Camadas Ocultas (16 e 8 neur√¥nios) com ativa√ß√£o **ReLU**.
¬† ¬† * Regulariza√ß√£o **Dropout** (0.25) e **L2** para prevenir *overfitting*.
¬† ¬† * Camada de Sa√≠da (1 neur√¥nio) com ativa√ß√£o **Sigmoid** para a probabilidade bin√°ria.
    
5.¬† **Treinamento:** O modelo foi compilado com *loss* `binary_crossentropy` e otimizador `adam`, e treinado com *Early Stopping* (garantindo o uso dos melhores pesos).

6.¬† **Avalia√ß√£o:** O desempenho do **modelo final (com os pesos restaurados da melhor √©poca)** foi medido no conjunto de teste.

---

## üìä 4. Resultados Obtidos

A avalia√ß√£o do modelo no conjunto de teste (**61 amostras**) revelou um desempenho robusto e, o mais importante, clinicamente relevante.

Os gr√°ficos abaixo ilustram a efic√°cia do *Early Stopping*. Note que, embora o treino tenha continuado at√© a **√âpoca 31** (quando a paci√™ncia de 11 √©pocas se esgotou), a perda de valida√ß√£o (`val_loss`, laranja) claramente atingiu seu ponto m√≠nimo na **√âpoca 20** e come√ßou a subir, indicando overfitting. Gra√ßas ao `restore_best_weights=True`, as m√©tricas de avalia√ß√£o a seguir **referem-se ao modelo √≥timo da √âpoca 20**, e n√£o ao modelo degradado da √âpoca 31.

<img width="1616" height="496" alt="image" src="https://github.com/user-attachments/assets/9ad21f30-feb0-4de8-a0e8-764bf28d8ffc" />
**Obs:** Os pesos considerados para o modelo final foram os da melhor √©poca, que nesse caso foi a **20** e indicada no gr√°fico como **√≠ndice 19**.


### M√©tricas de Performance

| M√©trica | Resultado (Teste) | Interpreta√ß√£o |
| :--- | :--- | :--- |
| **Acur√°cia** | **83.61%** | O modelo acertou a classifica√ß√£o de 51 dos 61 pacientes. |
| **Precis√£o (Classe 1)** | **84.85%** | Das vezes que o modelo previu "Com Doen√ßa", ele acertou 84.85% das vezes. |
| **Recall (Classe 1)** | **84.85%** | O modelo identificou corretamente 84.85% de todos os pacientes que **realmente** tinham a doen√ßa. |

### Matriz de Confus√£o

A matriz de confus√£o detalha os acertos e erros:

<img width="952" height="803" alt="image" src="https://github.com/user-attachments/assets/855c8f39-030f-4ab2-bdd2-0581d3d838c3" />

* **Verdadeiros Positivos (TP): 28**
¬† ¬† * O modelo acertou 28 pacientes que tinham doen√ßa.
* **Verdadeiros Negativos (TN): 23**
¬† ¬† * O modelo acertou 23 pacientes que *n√£o* tinham doen√ßa.
* **Falsos Negativos (FN): 5**
¬† ¬† * O modelo **errou 5 pacientes** que tinham doen√ßa, mas foram classificados como saud√°veis.
* **Falsos Positivos (FP): 5**
¬† ¬† * O modelo errou 5 pacientes que eram saud√°veis, mas foram classificados como doentes.

---

## üî≠ 5. Conclus√£o

O resultado mais importante √© o **Recall de 84.85%**. Em um cen√°rio de diagn√≥stico m√©dico, √© muito mais grave cometer um Falso Negativo (n√£o detectar a doen√ßa) do que um Falso Positivo.

O modelo demonstrou ser altamente sens√≠vel, minimizando o erro mais perigoso (apenas 5 Falsos Negativos). A acur√°cia final de **83.61%** no conjunto de teste, combinada com a baixa diferen√ßa entre as curvas de treino e valida√ß√£o (resultado direto do uso de *Dropout* e do *Early Stopping* com `restore_best_weights=True`), indica que o **modelo final (da √âpoca 20)** generaliza bem para dados novos.

A normaliza√ß√£o dos dados foi um passo fundamental; sem ela, as *features* com grandes magnitudes (como `chol`) teriam impedido o otimizador `adam` de convergir para uma solu√ß√£o eficaz.
