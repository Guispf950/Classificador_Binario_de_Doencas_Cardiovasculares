# Projeto 1: ClassificaÃ§Ã£o BinÃ¡ria de DoenÃ§as CardÃ­acas com Redes Neurais

**Disciplina:** Fundamentos de InteligÃªncia Artificial (FIA)
**Professor:** Edjard Mota

## ğŸ‘¥ Equipe

- ANDRÃ‰ MALMSTEEN OLIVEIRA AMORIM
- BENJAMIM ISAAC RIBEIRO LIMA
- DIEGO GABRIEL SILVA AZEVEDO
- GUILHERME DA SILVA PEREIRA
- LETÃCIA ARAÃšJO
- MANFRED LIMA VEIGA
---

## ğŸ“‹ SumÃ¡rio
* [1. Sobre o Projeto](#1-sobre-o-projeto)
* [2. AdaptaÃ§Ãµes e Melhorias](#2-adaptaÃ§Ãµes-e-melhorias)
* [3. Fluxo de Trabalho do Notebook](#3-fluxo-de-trabalho-do-notebook)
* [4. Resultados Obtidos](#4-resultados-obtidos)
* [5. ConclusÃ£o](#5-conclusÃ£o)

---

## ğŸ’¡ 1. Sobre o Projeto

Este projeto consiste na implementaÃ§Ã£o de uma Rede Neural Artificial (ANN) *feedforward* para atuar como um **classificador binÃ¡rio**. O objetivo Ã© prever a presenÃ§a (1) ou ausÃªncia (0) de doenÃ§a cardÃ­aca em um paciente com base em um conjunto de atributos clÃ­nicos.

### O Problema

As doenÃ§as cardiovasculares sÃ£o a principal causa de morte em todo o mundo, tornando a detecÃ§Ã£o precoce um desafio crÃ­tico para a saÃºde pÃºblica. O desenvolvimento de modelos preditivos precisos pode auxiliar profissionais de saÃºde a identificar pacientes em risco, permitindo intervenÃ§Ãµes mais rÃ¡pidas e eficazes.

### O Dataset

O modelo foi treinado e avaliado utilizando o dataset **Heart Disease UCI**, obtido via Kaggle. ApÃ³s um rigoroso processo de limpeza, que incluiu a remoÃ§Ã£o de **723 registros duplicados**, o dataset final consistiu em **302 amostras Ãºnicas**.

* **Features (X):** 13 atributos clÃ­nicos, como idade, sexo, nÃ­vel de colesterol (`chol`), tipo de dor no peito (`cp`) e pressÃ£o arterial (`trestbps`).
* **Target (y):** A variÃ¡vel-alvo (`target`), onde 0 indica ausÃªncia de doenÃ§a e 1 indica a presenÃ§a.

---

## ğŸš€ 2. AdaptaÃ§Ãµes e Melhorias

Este notebook foi desenvolvido com base nas instruÃ§Ãµes da disciplina (Tema1-Trabalho-RedesNeurais.pdf) e adaptado do notebook base *'Heart Disease Prediction using Neural Networks'* (disponÃ­vel no Kaggle).

Foram realizadas as seguintes modificaÃ§Ãµes e melhorias tÃ©cnicas em relaÃ§Ã£o ao cÃ³digo base:

1.Â  **Foco em ClassificaÃ§Ã£o BinÃ¡ria:** O notebook original explorava tanto a classificaÃ§Ã£o categÃ³rica (mÃºltiplos nÃ­veis de doenÃ§a) quanto a binÃ¡ria. Conforme as instruÃ§Ãµes do trabalho, este projeto foi focado estritamente na **classificaÃ§Ã£o binÃ¡ria** (0 vs 1), tratando qualquer diagnÃ³stico de doenÃ§a como classe "1".
2.Â  **RemoÃ§Ã£o de Duplicatas:** Foi identificada e executada a remoÃ§Ã£o de **723 linhas duplicadas** (o dataset original do Kaggle tinha 1025 linhas), uma etapa de prÃ©-processamento crucial que nÃ£o estava no notebook original, garantindo a integridade e a validade estatÃ­stica do modelo (302 amostras restantes).
3.Â  **ImplementaÃ§Ã£o de *Early Stopping*:** Para combater o *overfitting* e otimizar o tempo de treinamento, foi adicionado um *callback* `EarlyStopping` do Keras.
Â  Â  * O modelo foi configurado para rodar por atÃ© **60 Ã©pocas**, monitorando a `val_loss`.
Â  Â  * O treinamento foi interrompido automaticamente na **Ã‰poca 31**, pois a acurÃ¡cia de validaÃ§Ã£o nÃ£o melhorou por **11 Ã©pocas** (paciÃªncia).
Â  Â  * Crucialmente, a opÃ§Ã£o `restore_best_weights=True` foi ativada, garantindo que o modelo final utilizado para avaliaÃ§Ã£o fosse aquele com os pesos da **Ã‰poca 20**, que apresentou o melhor desempenho de generalizaÃ§Ã£o.

---

## ğŸ§© 3. Fluxo de Trabalho do Notebook

O notebook segue o fluxo padrÃ£o de um projeto de *Deep Learning*:

1.Â  **Carga e Limpeza:** Os dados sÃ£o carregados via API do Kaggle e limpos (remoÃ§Ã£o de 723 duplicatas).
2.Â  **AnÃ¡lise ExploratÃ³ria (EDA):** VerificaÃ§Ã£o de tipos de dados, balanceamento de classe (**54,3%** vs **45,7%**, bem balanceado) e anÃ¡lise de correlaÃ§Ã£o.
3.Â  **PrÃ©-processamento:**
Â  Â  * DivisÃ£o dos dados em treino (80% / **241 amostras**) e teste (20% / **61 amostras**).
Â  Â  * **NormalizaÃ§Ã£o (PadronizaÃ§Ã£o):** AplicaÃ§Ã£o do `StandardScaler` *apÃ³s* a divisÃ£o (fit no treino, transform no teste) para evitar *data leakage*. Este passo Ã© essencial devido Ã s diferentes escalas das *features* (ex: `age` vs `chol`).
4.Â  **ConstruÃ§Ã£o do Modelo (Keras):** A ANN foi construÃ­da com:
Â  Â  * Camada de Entrada (13 neurÃ´nios)
Â  Â  * 2 Camadas Ocultas (16 e 8 neurÃ´nios) com ativaÃ§Ã£o **ReLU**.
Â  Â  * RegularizaÃ§Ã£o **Dropout** (0.25) e **L2** para prevenir *overfitting*.
Â  Â  * Camada de SaÃ­da (1 neurÃ´nio) com ativaÃ§Ã£o **Sigmoid** para a probabilidade binÃ¡ria.
5.Â  **Treinamento:** O modelo foi compilado com *loss* `binary_crossentropy` e otimizador `adam`, e treinado com *Early Stopping*.
6.Â  **AvaliaÃ§Ã£o:** O desempenho do modelo foi medido no conjunto de teste.

---

## ğŸ“Š 4. Resultados Obtidos

A avaliaÃ§Ã£o do modelo no conjunto de teste (**61 amostras**) revelou um desempenho robusto e, o mais importante, clinicamente relevante:

<img width="1616" height="496" alt="image" src="https://github.com/user-attachments/assets/9ad21f30-feb0-4de8-a0e8-764bf28d8ffc" />

### MÃ©tricas de Performance

| MÃ©trica | Resultado (Teste) | InterpretaÃ§Ã£o |
| :--- | :--- | :--- |
| **AcurÃ¡cia** | **83.61%** | O modelo acertou a classificaÃ§Ã£o de 51 dos 61 pacientes. |
| **PrecisÃ£o (Classe 1)** | **84.85%** | Das vezes que o modelo previu "Com DoenÃ§a", ele acertou 84.85% das vezes. |
| **Recall (Classe 1)** | **84.85%** | O modelo identificou corretamente 84.85% de todos os pacientes que **realmente** tinham a doenÃ§a. |

### Matriz de ConfusÃ£o

A matriz de confusÃ£o detalha os acertos e erros:

<img width="952" height="803" alt="image" src="https://github.com/user-attachments/assets/855c8f39-030f-4ab2-bdd2-0581d3d838c3" />

* **Verdadeiros Positivos (TP): 28**
Â  Â  * O modelo acertou 28 pacientes que tinham doenÃ§a.
* **Verdadeiros Negativos (TN): 23**
Â  Â  * O modelo acertou 23 pacientes que *nÃ£o* tinham doenÃ§a.
* **Falsos Negativos (FN): 5**
Â  Â  * O modelo **errou 5 pacientes** que tinham doenÃ§a, mas foram classificados como saudÃ¡veis.
* **Falsos Positivos (FP): 5**
Â  Â  * O modelo errou 5 pacientes que eram saudÃ¡veis, mas foram classificados como doentes.

---

## ğŸ”­ 5. ConclusÃ£o

O resultado mais importante Ã© o **Recall de 84.85%**. Em um cenÃ¡rio de diagnÃ³stico mÃ©dico, Ã© muito mais grave cometer um Falso Negativo (nÃ£o detectar a doenÃ§a) do que um Falso Positivo.

O modelo demonstrou ser altamente sensÃ­vel, minimizando o erro mais perigoso (apenas 5 Falsos Negativos). A acurÃ¡cia final de **83.61%** no conjunto de teste, combinada com a baixa diferenÃ§a entre as curvas de treino e validaÃ§Ã£o (graÃ§as ao *Dropout* e *Early Stopping*), indica que o modelo generaliza bem para dados novos.

A normalizaÃ§Ã£o dos dados foi um passo fundamental; sem ela, as *features* com grandes magnitudes (como `chol`) teriam impedido o otimizador `adam` de convergir para uma soluÃ§Ã£o eficaz.
